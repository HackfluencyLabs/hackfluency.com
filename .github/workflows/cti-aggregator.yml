name: CTI Aggregator - Threat Intelligence Pipeline

on:
  workflow_dispatch:
    inputs:
      run_scrapers:
        description: 'Ejecutar scrapers (X + Shodan)'
        required: true
        default: 'true'
        type: boolean
      use_cache:
        description: 'Usar cache si existe (24h TTL)'
        required: true
        default: true
        type: boolean

permissions:
  contents: write

concurrency:
  group: "cti-aggregator"
  cancel-in-progress: false

env:
  CTI_CACHE_DIR: ${{ github.workspace }}/DATA/cti-cache
  CTI_OUTPUT_DIR: ${{ github.workspace }}/DATA/cti-output
  # Use qwen2.5:3b for CTI - faster inference on CPU runners, good reasoning
  OLLAMA_MODEL: qwen2.5:3b

jobs:
  cti-pipeline:
    name: CTI Pipeline
    runs-on: ubuntu-latest
    timeout-minutes: 35
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Cache Ollama Model
        uses: actions/cache@v4
        with:
          path: ~/.ollama
          key: ollama-${{ env.OLLAMA_MODEL }}

      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          sleep 10
          ollama pull ${{ env.OLLAMA_MODEL }}
          echo "Testing model availability..."
          curl -s http://localhost:11434/api/generate -d '{"model":"${{ env.OLLAMA_MODEL }}","prompt":"test","stream":false,"options":{"num_predict":1}}' | head -c 200
          echo ""

      - name: Restore CTI Cache
        if: ${{ inputs.use_cache }}
        uses: actions/cache@v4
        with:
          path: ${{ env.CTI_CACHE_DIR }}
          key: cti-data-${{ github.run_id }}
          restore-keys: cti-data-

      - name: Setup Directories
        run: mkdir -p ${{ env.CTI_CACHE_DIR }} ${{ env.CTI_OUTPUT_DIR }}

      - name: Install Dependencies
        working-directory: ./scripts/cti
        run: npm ci

      - name: Install Playwright (Chromium only)
        if: ${{ inputs.run_scrapers }}
        run: npx playwright install chromium --with-deps

      - name: Setup X Cookies
        if: ${{ inputs.run_scrapers }}
        run: |
          mkdir -p ./DATA
          echo '${{ secrets.X_COOKIES_JSON }}' > ./DATA/x-cookies.json

      # Single pipeline execution with context-aware flow:
      # 1. X.com scrape → 2. QueryGenerator → 3. Contextual Shodan → 4. Process → 5. CTI Analysis → 6. Dashboard
      - name: Run CTI Pipeline (Context-Aware)
        working-directory: ./scripts/cti
        env:
          SHODAN_API_KEY: ${{ secrets.SHODAN_API_KEY }}
          X_COOKIES_PATH: ${{ github.workspace }}/DATA/x-cookies.json
          USE_CACHE: ${{ inputs.use_cache }}
          OLLAMA_HOST: http://localhost:11434
          OLLAMA_MODEL: ${{ env.OLLAMA_MODEL }}
          CTI_PUBLIC_DIR: ${{ github.workspace }}/eccentric-equator/public/data
        run: npx tsx src/index.ts all

      - name: Save Cache
        uses: actions/cache/save@v4
        if: always()
        with:
          path: ${{ env.CTI_CACHE_DIR }}
          key: cti-data-${{ github.run_id }}

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: cti-report-${{ github.run_number }}
          path: ${{ env.CTI_OUTPUT_DIR }}/
          retention-days: 14
          if-no-files-found: warn

      - name: Commit Dashboard Update
        run: |
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"
          git add ./eccentric-equator/public/data/cti-dashboard.json || true
          git diff --staged --quiet || git commit -m "chore: update CTI intelligence dashboard"
          git push || true
